{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4LE1w8FMBgSy",
    "outputId": "9ef0daac-6f2f-45fa-cf5d-c122e8a58320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSE_487_587_Assignment_3___Predictive_Analytics_with_Apache_Spark.pdf\r\n",
      "Data\r\n",
      "Desktop\r\n",
      "DIC\r\n",
      "DIC_PySpark_Part3.ipynb\r\n",
      "Documents\r\n",
      "Downloads\r\n",
      "examplehadoop\r\n",
      "examples.desktop\r\n",
      "genre_lables.csv\r\n",
      "gutenberg\r\n",
      "hadoop-2.8.5.tar.gz\r\n",
      "hadoop-3.1.2\r\n",
      "hadoop-3.1.2.tar.gz\r\n",
      "hadooptmpdata\r\n",
      "hdfs\r\n",
      "hs_err_pid10739.log\r\n",
      "hs_err_pid24575.log\r\n",
      "hs_err_pid24640.log\r\n",
      "mapping.csv\r\n",
      "Music\r\n",
      "part3\r\n",
      "Pictures\r\n",
      "Public\r\n",
      "sample.csv\r\n",
      "spark-2.4.0-bin-hadoop2.7\r\n",
      "spark-2.4.0-bin-hadoop2.7.tgz\r\n",
      "Templates\r\n",
      "test.csv\r\n",
      "train.csv\r\n",
      "Untitled-1.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "Videos\r\n"
     ]
    }
   ],
   "source": [
    "##TO RUN THE FILE GOOGLE COLAB\n",
    "import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')     ##TO RUN THE FILE ON\n",
    "# findspark.init()                                           ##TO RUN THE FILE GOOGLE COLAB\n",
    "from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark = SparkSession.builder.master(\"local[*]\")\\\n",
    "        .config(\"spark.executor.memory\", \"2g\")\\\n",
    "        .config(\"spark.driver.memory\", \"2g\")\\\n",
    "        .config(\"spark.memory.offHeap.enabled\",'true')\\\n",
    "        .config(\"spark.memory.offHeap.size\",\"2g\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_2-mSqruBAg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.functions import regexp_replace,col,array_contains,explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel\n",
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7yuAm0Vqvw-"
   },
   "outputs": [],
   "source": [
    "pd_df = pd.read_csv(r'train.csv')\n",
    "data_spark_df = spark.createDataFrame(pd_df)\n",
    "pd_df['genre']= pd_df['genre'].apply(literal_eval)\n",
    "all_genre = pd_df['genre'].to_list()\n",
    "names =['Drama','Comedy','Romance Film','Thriller','Action','World cinema','Crime Fiction','Horror','Black-and-white','Indie','Action/Adventure','Adventure','Family Film','Short Film','Romantic drama','Animation','Musical','Science Fiction','Mystery','Romantic comedy']\n",
    "matrix = np.zeros((len(pd_df),len(names)))\n",
    "\n",
    "for i,genre in enumerate(all_genre):\n",
    "  for j,g in enumerate(genre):\n",
    "    for k,name in enumerate(names):\n",
    "        if name==g:\n",
    "          matrix[i][k] = 1\n",
    "names = \"Drama , Comedy , Romance Film , Thriller , Action , World cinema , Crime Fiction , Horror , Black-and-white , Indie , Action/Adventure , Adventure , Family Film , Short Film , Romantic drama , Animation , Musical , Science Fiction , Mystery , Romantic comedy\"\n",
    "np.savetxt(\"genre_lables.csv\", matrix, delimiter=\",\",fmt='%d',header=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MxifttVqz59"
   },
   "outputs": [],
   "source": [
    "lables_df = pd.read_csv(r'genre_lables.csv')\n",
    "test_pd_df = pd.read_csv(r'test.csv')\n",
    "lables_spark_df = spark.createDataFrame(lables_df)\n",
    "test_spark_df = spark.createDataFrame(test_pd_df)\n",
    "ddf1 = data_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "ddf2 = lables_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "ddf3 = test_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "df = ddf1.join(ddf2, \"row_id\").drop(\"row_id\")\n",
    "test_df = ddf3.join(ddf2, \"row_id\").drop(\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8NlOMKtyq4Om",
    "outputId": "74011e9f-dda5-47fc-ace9-59ac4410fdc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 23.9 ms, total: 132 ms\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(inputCol=\"plot\", outputCol=\"words\")\n",
    "word2Vec = Word2Vec(inputCol=\"words\", outputCol=\"features\", minCount=1)\n",
    "pipeline = Pipeline(stages=[tokenizer, word2Vec])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "dataset = model.transform(df)\n",
    "\n",
    "model2 = pipeline.fit(test_df)\n",
    "test_dataset = model2.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = []\n",
    "labelCols = lables_spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PCiHqUONlKTZ",
    "outputId": "a8db1ceb-66d4-4f9e-d8d6-c68364356244"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "##Note: Run this cell if you wann train the model again\n",
    "lr = LogisticRegression(featuresCol = 'features',maxIter=750)\n",
    "for labelCol in labelCols:\n",
    "    lr.setLabelCol(labelCol)\n",
    "    lrModel = lr.fit(dataset)\n",
    "    lrModel.save(r\"part3/\"+labelCol) ##\"\"\" if you want train the model again comment this line and uncomment the next following line\"\"\"\n",
    "    # lrModel.write().overwrite().save(r\"part3/\"+labelCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Xgzq44eJlOLu",
    "outputId": "cd658360-3012-4c49-cc9d-fb5880fa2d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 ms, sys: 59.7 ms, total: 503 ms\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel\n",
    "for labelCol in labelCols:\n",
    "    lrModel2 = LogisticRegressionModel.load(\"part3/\"+labelCol)\n",
    "    predictions = lrModel2.transform(test_dataset)\n",
    "    predictions = predictions.drop(\"features\",labelCol,\"rawPrediction\",\"probability\")\n",
    "    predictions = predictions.withColumn(\"prediction\",F.col(\"prediction\").cast(IntegerType()))\n",
    "    dfList.append(predictions.select(\"movie_id\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "d6AYBQciq9a9",
    "outputId": "791d85ce-bffc-4a97-8b29-76b8fd7c2ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 709 ms, sys: 142 ms, total: 851 ms\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs_renamed = [df.selectExpr('movie_id', f'prediction as prediction_{i}') for i, df in enumerate(dfList)]\n",
    "temp_df = reduce(lambda x, y: x.join(y, ['movie_id'], how='full'), dfs_renamed)\n",
    "col_list = ['prediction_%d' % i for i in range(len(dfList))]\n",
    "temp_df = temp_df.withColumn('predictions',concat_ws(\" \",*col_list)).drop(*col_list).toPandas().to_csv(\"predictions_part3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DIC_PySpark_Part3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
